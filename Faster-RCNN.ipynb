{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPSED_intern.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2ASA16MHfX0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "58fcfd23-6544-432a-8157-da94d02a52c6"
      },
      "source": [
        "%%shell\n",
        "pip install cython\n",
        "pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "mkdir dataset\n",
        "%%shell\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.3.0\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.21)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-b2nkwco6\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-b2nkwco6\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (49.1.0)\n",
            "Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (0.29.21)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.12.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp36-cp36m-linux_x86_64.whl size=266453 sha256=68ab3277d7dca822748663c3dc73bd098a493299e27bd074cd5626babad10f78\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fg5w4z4b/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Found existing installation: pycocotools 2.0\n",
            "    Uninstalling pycocotools-2.0:\n",
            "      Successfully uninstalled pycocotools-2.0\n",
            "Successfully installed pycocotools-2.0\n",
            "/bin/bash: line 3: fg: no job control\n",
            "fatal: destination path 'vision' already exists and is not an empty directory.\n",
            "HEAD is now at be37608 version check against PyTorch's CUDA version\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sCYrZF3T1Dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from PIL import Image\n",
        "import xml.etree.ElementTree as ET\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etz0tLBOHmQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_bad_photos(root_dir):\n",
        "  annotations = list(sorted(os.listdir(os.path.join(root_dir, \"Annotations\")))) \n",
        "  images = list(sorted(os.listdir(os.path.join(root_dir, \"Images\"))))\n",
        "  for ann in annotations:\n",
        "    ann_path = os.path.join(root_dir, \"Annotations\", ann)\n",
        "    img_path = os.path.join(root_dir, \"Images\", os.path.splitext(os.path.basename(ann_path))[0] +'.jpg')\n",
        "    LList = []\n",
        "    LL = []\n",
        "    line_count = 0\n",
        "    with open(ann_path,'r') as csv_file:\n",
        "\t    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "\t    for row in csv_reader:\n",
        "\t\t    LList = []\n",
        "\t\t    for i in row:\n",
        "\t\t\t    data = i.split(\" \")\n",
        "\t\t\t    for j in data:\n",
        "\t\t\t\t    LList.append(int(j))\n",
        "\t\t    LL.append(LList)\n",
        "\t\t    line_count += 1\n",
        "    boxes = np.array(LL[1:])\n",
        "    num_objs = LL[0][0]\n",
        "    if num_objs < 1:\n",
        "      os.remove(ann_path)\n",
        "      os.remove(img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD_ZjQ6zHuGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "remove_bad_photos('dataset/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI7iVTQTHuqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transforms=None):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        # load all image files, sorting them to\n",
        "        # ensure that they are aligned\n",
        "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"Images\"))))\n",
        "        self.annotations = list(sorted(os.listdir(os.path.join(root, \"Annotations\"))))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # load images ad masks\n",
        "        img_path = os.path.join(self.root, \"Images\", self.imgs[idx])\n",
        "        ann_path = os.path.join(self.root, \"Annotations\", self.annotations[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        LList = []\n",
        "        LL = []\n",
        "        line_count = 0\n",
        "        with open(ann_path,'r') as csv_file:\n",
        "\t        csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "\t        for row in csv_reader:\n",
        "\t\t        LList = []\n",
        "\t\t        for i in row:\n",
        "\t\t\t        data = i.split(\" \")\n",
        "\t\t\t        for j in data:\n",
        "\t\t\t\t        LList.append(int(j))\n",
        "\t\t        LL.append(LList)\n",
        "\t\t        line_count += 1\n",
        "        boxes = np.array(LL[1:])\n",
        "        num_objs = LL[0][0]\n",
        "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "        image_id = torch.tensor([idx])\n",
        "        \n",
        "        if num_objs < 1:\n",
        "          target = {}\n",
        "          target[\"boxes\"] = torch.as_tensor(np.zeros(4), dtype=torch.float32)\n",
        "          target[\"labels\"] = labels\n",
        "          target[\"image_id\"] = image_id\n",
        "          target[\"area\"] = 0\n",
        "          target[\"iscrowd\"] = iscrowd\n",
        "\n",
        "          if self.transforms is not None:\n",
        "              img, target = self.transforms(img, target)\n",
        "          return img, target\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img, target = self.transforms(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9uBn_OxH02S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomDatasetTest(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transforms=None):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"Images\"))))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # load images ad masks\n",
        "        img_path = os.path.join(self.root, \"Images\", self.imgs[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        target = {}\n",
        "        if self.transforms is not None:\n",
        "            img, target = self.transforms(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPM9oAK4H7lW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Model(num_classes):\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features,  num_classes)\n",
        "    return model\n",
        "\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    transforms.append(T.ToTensor())\n",
        "    if train:\n",
        "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "    return T.Compose(transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnDYu9LHIMTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = CustomDataset('dataset/', get_transform(train=True))\n",
        "dataset_test = CustomDataset('dataset/', get_transform(train=False))\n",
        "num_classes = 20\n",
        "\n",
        "torch.manual_seed(1)\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset = torch.utils.data.Subset(dataset, indices[0:-50])\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True, num_workers=4, collate_fn=utils.collate_fn)\n",
        "data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=4, collate_fn=utils.collate_fn)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model = Model(num_classes)\n",
        "model.to(device)\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "    lr_scheduler.step()\n",
        "    evaluate(model, data_loader_test, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3L7rmfyI8lO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img,_ = dataset_test[0]\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    prediction = model([img.to(device)])\n",
        "\n",
        "img = Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())\n",
        "box = prediction[0]['boxes'].cpu().numpy()\n",
        "scores = prediction[0]['scores'].cpu().numpy()\n",
        "fig,ax = plt.subplots(1)\n",
        "ax.imshow(img)\n",
        "rect = []\n",
        "for i in range (int(box.size/4)):\n",
        "  if scores[i]>0.3:\n",
        "    rect = patches.Rectangle((box[i][0], box[i][1]),(box[i][2]-box[i][0]),(box[i][3]-box[i][1]),linewidth=1,edgecolor='r',facecolor='none')\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}